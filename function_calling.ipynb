{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load the dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (1.35.5)\n",
      "Requirement already satisfied: langchain in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (0.2.6)\n",
      "Requirement already satisfied: langchain-community in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (0.2.6)\n",
      "Requirement already satisfied: pinecone-client in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (3.2.2)\n",
      "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (1.0.1)\n",
      "Requirement already satisfied: tiktoken in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (0.7.0)\n",
      "Requirement already satisfied: docx2txt in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (0.8)\n",
      "Requirement already satisfied: pypdf in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (4.2.0)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (2.32.3)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 10)) (2.2.2)\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 11)) (3.9.5)\n",
      "Requirement already satisfied: pyYAML in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 12)) (6.0.1)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 13)) (1.26.4)\n",
      "Requirement already satisfied: langchain-huggingface in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 14)) (0.0.3)\n",
      "Requirement already satisfied: huggingface_hub in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 15)) (0.23.4)\n",
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 16)) (4.41.2)\n",
      "Requirement already satisfied: accelerate in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 17)) (0.31.0)\n",
      "Requirement already satisfied: bitsandbytes in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 18)) (0.42.0)\n",
      "Requirement already satisfied: gradio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 20)) (4.37.1)\n",
      "Requirement already satisfied: langchain-pinecone in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 21)) (0.1.1)\n",
      "Requirement already satisfied: chromadb in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 22)) (0.5.3)\n",
      "Requirement already satisfied: lark in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 23)) (1.1.9)\n",
      "Collecting openapi-python-generator (from -r requirements.txt (line 24))\n",
      "  Using cached openapi_python_generator-0.5.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement inspect (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for inspect\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Load environment variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "\n",
    "token = os.environ['HUGGINGFACEHUB_API_TOKEN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Get the openapi.yml from open-mateo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-07-02 22:43:10--  https://raw.githubusercontent.com/open-meteo/open-meteo/main/openapi.yml\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8003::154, 2606:50c0:8002::154, 2606:50c0:8001::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8003::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13300 (13K) [text/plain]\n",
      "Saving to: ‘openapi.yml.1’\n",
      "\n",
      "openapi.yml.1       100%[===================>]  12.99K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-07-02 22:43:10 (112 MB/s) - ‘openapi.yml.1’ saved [13300/13300]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/open-meteo/open-meteo/main/openapi.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import json\n",
    "\n",
    "# Read the content of the file\n",
    "with open('openapi.yml', 'r') as file:\n",
    "    file_content = file.read()\n",
    "file_content = file_content.replace(\"int\\n\", \"number\\n\")\n",
    "file_content = file_content.replace(\"float\\n\", \"number\\n\")\n",
    "data = yaml.safe_load(file_content)\n",
    "\n",
    "data[\"servers\"] = [{\"url\": \"https://api.open-meteo.com\"}]\n",
    "\n",
    "with open('openapi.json', 'w') as file:\n",
    "    json_content = json.dump(data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Import the neccessary function `get_v1forecast` from open-mateo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: openapi-python-generator\n"
     ]
    }
   ],
   "source": [
    "!openapi-python-generator openapi.json ./api_specification_main/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from api_specification_main.services.WeatherForecastAPIs_service\\\n",
    "    import get_v1forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"Hey how is the current weather and windspeed in Charlotte?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(latitude: float, longitude: float, hourly: Optional[List[str]] = None, daily: Optional[List[str]] = None, current_weather: Optional[bool] = None, temperature_unit: Optional[str] = None, wind_speed_unit: Optional[str] = None, timeformat: Optional[str] = None, timezone: Optional[str] = None, past_days: Optional[int] = None, api_config_override: Optional[api_specification_main.api_config.APIConfig] = None) -> Dict[str, Any]\n",
      "\n",
      "Function:\n",
      "get_v1forecast(latitude: float, longitude: float, hourly: Optional[List[str]] = None, daily: Optional[List[str]] = None, current_weather: Optional[bool] = None, temperature_unit: Optional[str] = None, wind_speed_unit: Optional[str] = None, timeformat: Optional[str] = None, timezone: Optional[str] = None, past_days: Optional[int] = None, api_config_override: Optional[api_specification_main.api_config.APIConfig] = None) -> Dict[str, Any]\n",
      "\"\"\"\n",
      "Requires the latitude and longitude.\n",
      "Set current_weather to True to get the weather.\n",
      "Set hourly or daily based on preference.\n",
      "Return ONLY the function call with the latitude and longitude of the location and no other explanation so I can eval the function directly.\n",
      "Example \"get_v1forecast(latitude=40.7128, longitude=-74.0060, current_weather=True)\" as response ONLY, no other text.\n",
      "Respond in JSON mode with function under the key \"result\" and value as function string.\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "User Query: Hey how is the current weather and windspeed in Charlotte?<human_end>\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "signature = inspect.signature(get_v1forecast)\n",
    "print(signature)\n",
    "docstring = \\\n",
    "    '''\n",
    "Requires the latitude and longitude.\n",
    "Set current_weather to True to get the weather.\n",
    "Set hourly or daily based on preference.\n",
    "Return ONLY the function call with the latitude and longitude of the location and no other explanation so I can eval the function directly.\n",
    "Example \"get_v1forecast(latitude=40.7128, longitude=-74.0060, current_weather=True)\" as response ONLY, no other text.\n",
    "Respond in JSON mode with function under the key \"result\" and value as function string.\n",
    "\n",
    "'''\n",
    "\n",
    "prompt = \\\n",
    "    f'''\n",
    "Function:\n",
    "{get_v1forecast.__name__}{signature}\n",
    "\"\"\"{docstring}\"\"\"\n",
    "\n",
    "User Query: {user_query}<human_end>'''\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Use Ollama with lllama3 model and Function Calling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama\n",
    "llm = Ollama(temperature=0, model=\"llama3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Calling\n",
    "\n",
    "The LLM does not have the latest info. However, it knows the function calling based on the api spec provided to it with the prompt. So it returns the method signature that we can use to call the function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"result\": \"get_v1forecast(latitude=35.2278, longitude=-80.8431, current_weather=True)\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Print the Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': 'get_v1forecast(latitude=35.2278, longitude=-80.8431, current_weather=True)'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = json.loads(response)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = eval(r[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather Information:\n",
      "Time: 2024-07-03T02:30\n",
      "Temperature: 24.1°C\n",
      "Wind Speed: 6.9 km/h\n",
      "Wind Direction: 81°\n",
      "Day/Night: Night\n"
     ]
    }
   ],
   "source": [
    "temperature = data['current_weather']['temperature']\n",
    "windspeed = data['current_weather']['windspeed']\n",
    "winddirection = data['current_weather']['winddirection']\n",
    "is_day = data['current_weather']['is_day']\n",
    "time = data['current_weather']['time']\n",
    "\n",
    "# Determine day or night\n",
    "day_or_night = 'Day' if is_day else 'Night'\n",
    "\n",
    "# Print the weather information nicely\n",
    "print(f\"Weather Information:\")\n",
    "print(f\"Time: {time}\")\n",
    "print(f\"Temperature: {temperature}°C\")\n",
    "print(f\"Wind Speed: {windspeed} km/h\")\n",
    "print(f\"Wind Direction: {winddirection}°\")\n",
    "print(f\"Day/Night: {day_or_night}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
